# Navigating the Risks of Using LLMs for Text Annotation  
*Code repository for* ‚ÄúNavigating the Risks of Using Large Language Models for Text Annotation in Social Science Research‚Äù (Social Science Computer Review)  

**Authors:** Hao Lin, Yongjun Zhang  
**Preprint / public version (arXiv):** *The Risks of Using Large Language Models for Text Annotation in Social Science Research*  
**Journal Link (Sage):** [https://journals.sagepub.com/doi/pdf/10.1177/08944393251366243](https://journals.sagepub.com/doi/pdf/10.1177/08944393251366243)  
**Preprint (arXiv):** [https://arxiv.org/abs/2503.22040](https://arxiv.org/abs/2503.22040)  

---

## üìò Overview & Purpose

This repository contains code, scripts, and resources used to generate results presented in the article. The overall goal is to support reproducibility, transparency, and extension of the analyses described in the paper.

In the article, the authors systematically evaluate the promises and risks of using LLMs (large language models) for text annotation tasks in computational social science, using social movement studies as a case example. They propose a framework for integrating LLMs into annotation workflows (either as primary decision-maker or as coding assistant), and they discuss how to assess and report validity, reliability, replicability, and epistemic risks. 

This codebase is intended to :

- replicate the key experiments and analyses from the article  
- apply the authors‚Äô prompt engineering, evaluation, and validation procedures to new data  
- explore sensitivity analyses, alternative models, or risk mitigation strategies  


